---
title: "Modelos con Coeficientes Variando"
author: "Bladimir Valerio Morales Torrez"
date: "Julio 2022"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

Los modelos aditivos generalizados (modelos no paramétricos), propuestos por @Hastie_Tibshirani_1986 dan a conocer una nueva clase de modelos de regresión, extendiendo y flexibilizando el modelo de regresión clásico, reemplazando la función lineal por una función aditiva suave y no paramétricas, la cual es estimada por el algoritmo de puntuación local (local scoring algorithm).  
Es así que,  @Hastie_Tibshirani_1993, proponen otra generalización al modelo de regresión lineal clásico, denominados modelos de coeficientes variando (Varying-Coefficient Models VCMs), los cuales contienen regresores lineales pero permiten que sus coeficientes cambien suavemente con el valor de otras variables, que se denominan "modificadores de efecto".

# Marco Teórico

## El modelo 

Supongamos que se tiene una variable aleatoria $Y$ cuya distribución depende de un parámetro $\eta$ que será el predictor lineal y se relaciona con la media $\mu=\mathbb{E}(Y)$ mediante la función enlace $\eta=g(\mu)$, el modelo lineal generalizado con coeficientes variando se puede representar como:
\begin{eqnarray}\label{modelo.general}
\eta_i=\beta_0+x_i^{1}\beta_1(t_{1_i})+\cdots+x_i^p\beta_p(t_{p_i})
\end{eqnarray}
Donde los $t_1,\cdots,t_p$ cambian los coeficientes de las covariables $x^1,\cdots,x^p$ a través de las funciones $\beta_1,\cdots,\beta_p$. La dependencia de $\beta_j$ en $t_j$, con $j=1,...,p$ implica un tipo de interacción entre $t_j$ y $x^j$, donde la variable $t_j$ puede no ser tan diferente a $x^j$, pero también $t_j$ puede ser una variable especial como el tiempo.  
Si se toma el modelo Gaussiano, donde $g(\mu)=\mu$ y la variable aleatoria $Y$ tiene distribución normal con media $\eta$, el modelo (\ref{modelo.general}) es de la forma

\begin{eqnarray}\label{modelo.normal}
Y_i=\beta_0+x_i^{1}\beta_1(t_{1_i})+\cdots+x_i^p\beta_p(t_{p_i})+\varepsilon_i
\end{eqnarray}

donde $\mathbb{E}(\varepsilon)=0$ y $Var(\varepsilon)=\sigma^2$

### Casos del modelo
El modelo de coeficientes variando generaliza los siguientes tipos de modelos:
a) Si $\beta_j(t_j)=\beta_j$ una función constante, entonces ese término es lineal en $x^j$. Si todos los términos son lineales se reduce a un modelo lineal generalizado clásico.  
b) Si $x^j=c$ con $c$ constante entonces el $j-ésimo$ término es $\beta_j(t_j)$ una función no conocida. Si todos los términos tienen esta característica se tiene un modelo aditivo generalizado.  
c) Una función lineal $\beta_j(t_j)=\beta_jt_j$ produce una interacción de la forma $\beta_jx^jt_j$.  
d) En el término del modelo $x\beta(t)$, cuando $x$ es una variable binaria ($0-1$). Supongamos que hay un término $\beta_0(t)$ en el modelo. Esto equivale a tener una curva separada correspondiente a cada uno de los dos valores de $x$.   
e) A menudo las $t_j$ serán la misma variable, como puede ser la edad o el tiempo, que podría modificar los efectos de $x^1,...,x^p$. Supongamos que, los datos consisten en mediciones repetidas de las variables $y, x^1 , ..., x^p$ sobre $n$ puntos de tiempo $t\in(t_1,...,t_n$ ) . Entonces podríamos modelar esto a lo largo del tiempo
$$\eta_{t,i} =\beta_0(t_i) +x^1 (t_{1_i})\beta_1(t_{1_i}) + ... +x^p (t_{p_i})\beta_p(t_{p_i})$$
Que es llamado como *modelo lineal generalizado dinámico* o *condicionalmente paramétricos*  
f) La variable modificante $t_j$ puede ser la misma que $x^j$, por simplicidad suponemos que es un modelo lineal normal con un solo término. 
$$y_i =x_i \beta_j(x_i) + \varepsilon$$
Este es un modelo común de suavizamiento o regresión no paramétrica de $Y$ versus $X$.  
g) Cada $t_j$ puede tener un valor escalar o vectorial.  
h) En todos los casos anteriores, hay muchas formas de modelar las funciones $\beta_j(t_j)$. Por ejemplo, podríamos usar representaciones paramétricas flexibles tales como polinomios, series de Fourier o polinomios por partes, o de manera más general  funciones no paramétricas, mediante el uso de métodos kernel, penalización o formulaciones bayesianas estocásticas.  

### Matricialmente

En términos matriciales el modelo seria de la siguiente forma:

\begin{eqnarray}\label{modelo.matricial}
\Yn=\tilde{N}_1\beta_1+\cdots+\tilde{N}_p\beta_p
\end{eqnarray}


donde, $\Yn$ es la variable de respuesta y $\Xn_i$ es una matriz diagonal de la variable de respuesta $x_i^j$ en su diagonal. 


## Estimación

El modelo (\ref{modelo.general}), es general para la mayoría de las aplicaciones, ya que no se imponen restricciones
a las funciones de los coeficientes. La estimación no paramétrica sin restricciones de estas funciones probablemente no sería posible, salvo en el caso de diseños especiales. En el caso de los datos observacionales, es probable que se vea un valor diferente para cada $t$, en cada muestra.   
Por esta razón, se impone restricciones a las funciones de los coeficientes variando, por ejemplo, a trozos con forma paramétrica conocida o bien suave pero no paramétrica. Una aproximación sería a través de bases paramétricas como funciones polinómicas o trigonométricas. Normalmente, éstas no proporcionan suficiente flexibilidad y adaptabilidad local, y es probable que un conjunto de bases de splines de regresión es preferible.  
Se procederá igual que con un modelo lineal, sólo que con varias variables definidas por los productos de cada $x$, y las bases de $\beta_j(t_j)$ con este enfoque, las herramientas inferenciales estándar sirven para evaluar conjuntos de coeficientes, puntos de influencia, etc. Las características de las curvas ajustadas pueden ser muy diferentes con pequeños cambios en las posiciones de los nudos, sobre todo si sólo se pueden permitir unos pocos.  
En este trabajo se mostrará el procedimiento para el modelo (\ref{modelo.normal}) ya que para el modelo (\ref{modelo.general})
incluyen procedimientos diferentes como el algoritmo de tipo NewtonRaphson.

### Mínimos Cuadrados Penalizados

Se tiene
$$\mathbb{E}\left\{y_i-\sum_{j=1}^{p}x_i^j \beta_j(t_{j_i})\right\}^2$$
Se condiciona en $t_j$, es una condición suficiente para la solución:

$$\mathbb{E}\left\{x^k_i\left\{y_i-\sum_{i=1\\i\neq k}^{p} x_i^j \beta_j(t_{j_i}) \right\}|t_k\right\}=0 \hspace{1cm}k=1,...,p$$


La ecuación (6) es una relación de dos esperanzas condicionales y puede verse como una media ponderada condicional, en la que las ponderaciones condicionales vienen dadas por el término XJ; el término en el denominador garantiza que las ponderaciones se integren en 1. Existe una ecuación ecuación similar para cada función (3i" j = 1, ..., p, y el conjunto de p ecuaciones debe resolver simultáneamente para la función (3i" j = 1 ..., p, como una estimación flexible de una esperanza condicional, esto sugiere que cada función (3j puede estimarse de forma iterativa "de uno en uno" mediante el alisado {Y-I:ki "jXk(3k(Rk)}IXj en R j, con pesos XJ. Esta es la idea central del marco formal que se discute a continuación


# Aplicación


Se utilizará los datos de los rendimientos diarios de las acciones de la General Electric Company y el índice de Standard & Poor's 500 (S&P 500). Los
están en el `data.frame` *capm* en el paquete `HRW`. La variable `Date` se tiene desde el 1 de noviembre de 1993 al 31 de marzo de 2003, por lo que hay más de nueve años de datos. Si $P_t$ es el precio de una acción en el día $t$, entonces el rendimiento logarítmico de ese día es $log(\frac{P_t}{P_{t−1}} )$. El exceso de rendimiento logarítmico es el rendimiento logarítmico menos la tasa de interés libre de riesgo, generalmente considerada como la tasa de facturación del Tesoro a corto plazo.  
El siguiente código calcula el rendimiento logarítmico excedente tanto de las acciones de General Electric Company como del índice S&P 500:

```{r}
library(HRW) 
data(capm)
n <- dim(capm)[1]
#riesgo.libre=riskfree
riesgo.libre <- capm$Close.tbill[2:n]/(100*365)
#elrGE=rend.log.ex.GE
rend.log.ex.GE <- diff(log(capm$Close.ge))-riesgo.libre
rend.log.ex.SP500 <- diff(log(capm$Close.sp500))-riesgo.libre

plot(rend.log.ex.GE)
plot(rend.log.ex.SP500)

hist(rend.log.ex.GE,freq = FALSE)
hist(rend.log.ex.SP500,freq = FALSE)

plot(rend.log.ex.GE,rend.log.ex.SP500)
```

Donde `capm$Close.sp500` y `capm$Close.ge` son los precios de cierre diarios y `capm$Close.tbill` es la tasa diaria de facturación del Tesoro expresada como porcentaje. En el código, `capm$Close.tbill` primero se divide por $100$ para convertir de un porcentaje a una fracción y luego se divide por $365$ para convertir de una tasa anual a una tasa diaria. Por eso, `rend.log.ex.GE` y `rend.log.ex.SP500` son los rendimientos logarítmicos excedentes diarios de las acciones de General Electric y en el índice S&P 500, respectivamente.  
Uno de los supuestos del modelo de fijación de precios de activos de capital en finanzas es que los rendimientos logarítmicos excedentes medios de una acción dependen linealmente de los rendimientos logarítmicos excedentes del mercado. El rendimiento del índice S&P 500 suele sera utilizado como proxy de la rentabilidad del mercado. Por lo general, el modelo de regresión lineal simple, se ajusta solo a datos recientes, ya que se espera que la pendiente cambie lentamente a lo largo del tiempo. Una alternativa es ajustar un modelo de coeficiente variando a todos los datos, con el intercepto y pendiente dependiendo de la fecha. Hacer esto proporcionaría evidencia como y con qué rapidez está cambiando la pendiente. La teoría económica predice que el intercepto es cero, por lo que se espera que el intercepto estimado sea insignificante. Primero, ajustamos un modelo de regresión lineal simple a todos los datos usando:

```{r}
library(mgcv)
fitSLR <- gam(rend.log.ex.GE ~ rend.log.ex.SP500)
summary(fitSLR)
```

Para verificar si un modelo lineal es apropiado, ajustamos el modelo de regresión no paramétrico del rendimiento logarítmico excedente de las acciones de General Electric que es una función suave e invariable en el tiempo del rendimiento logarítmico excedente del índice S&P 500. este modelo en comparación con el modelo lineal simple a través de una prueba $F$.

```{r}
fitNPR <- gam(rend.log.ex.GE ~ s(rend.log.ex.SP500),method = "REML")
summary(fitNPR)
anova(fitSLR,fitNPR,test = "F")
```

La prueba $F$ rechaza el modelo de regresión lineal simple. Sin embargo, el tamaño de la muestra es bastante grande ya que hubo $2362$ días de retornos y por lo tanto, hay un poder sustancial para detectar desviaciones de la linealidad. 


La gráfica de la regresión no paramétrica fit(fitNPR) se desvía solo ligeramente de una línea recta, al menos sobre el rango de la mayor parte de los datos. 

```{r}
plot(fitNPR)
```
Además, el ajuste suave tiene solo un poco más de $R^2-ajustado$, $56,4\%$, en comparación con el del modelo lineal, $55,9\%$. Cuando recurrimos a modelos de coeficientes variando, como suposición de trabajo supondremos que la regresión de los rendimientos logarítmicos excedentes de General Electric sobre los rendimientos logarítmicos excedentes del mercado es lineal, pero la intersección y la pendiente varían con el tiempo.  
Ahora, se ajusta y se grafica el modelo de coeficientes variando y lo comparamos con el modelo lineal de coeficientes constantes mediante una prueba $F$. En el modelo de coeficientes variando, el intercepto y la pendiente de la regresión lineal del logaritmo de retorno excedente de General Electric con el excedente de rendimiento logarítmico del índice S&P 500 son funciones suaves en el tiempo (años), almacenada como la variable $t$:

```{r}
dayNums <- (1:(n-1))/(n-1)
startTime <- 1993 + 11/12 #Noviembre
endTime <- 2003 + 3/12 #Marzo
t <- startTime + (endTime - startTime)*dayNums
fitVCM <- gam(rend.log.ex.GE ~ s(t) + s(t,by = rend.log.ex.SP500), method = "REML")
summary(fitVCM)
anova(fitSLR,fitVCM,test = "F")
```

Las funciones de intersección y pendiente se representan en la siguiente gráfica. El argumento seleccionado de gam() se usa para seleccionar qué componente trazar. El gráfico de código (fitVCM) sin el uso de seleccionar trazaría tanto la intersección como la pendiente pero usaría
la misma escala en el eje y, lo cual no permitiría especificar valores separados de `ylab` para las dos parcelas. El argumento `seWithMean = TRUE` se usa para especificar que los intervalos de confianza deben incluir la incertidumbre sobre la media. 

```{r}
par(mfrow=c(1,2))
plot(fitVCM,select = 1,ylim = c(-0.001,0.001),seWithMean = TRUE)
plot(fitVCM,select = 2,ylim = c(0.5,1.6),seWithMean = TRUE)
```

La estimación de la intersección sugiere que la intersección fue cero o casi nula, durante todo el período, lo que concuerda con la teoría económica. La pendiente estimada varía entre aproximadamente $1,0$ y $1,4$ durante este período. El modelo de regresión lineal simple se rechaza en favor del modelo de coeficientes variando, aunque el último proporciona solo una pequeña mejora en el ajuste medido por el $R^2-ajustado$.  













